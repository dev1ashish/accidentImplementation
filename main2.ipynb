{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Dependencies and Utilities\n",
    "- Download and import required libraries \n",
    "- Helper functions for video/image processing\n",
    "\n",
    "# Section 2: YOLO Implementation\n",
    "- Download YOLOv3 weights and config\n",
    "- Vehicle detection class and functions\n",
    "\n",
    "# Section 3: MOSSE Tracker\n",
    "- Complete MOSSE tracker implementation\n",
    "- Track-compensated frame interpolation (TCFI)\n",
    "\n",
    "# Section 4: Crash Estimation\n",
    "- Speed and trajectory estimation\n",
    "- Future position prediction\n",
    "- Collision detection algorithms\n",
    "\n",
    "# Section 5: ViF Descriptor & SVM\n",
    "- Horn-Schunck optical flow\n",
    "- ViF descriptor implementation\n",
    "- SVM training and prediction\n",
    "- (Optional commented training code)\n",
    "\n",
    "# Section 6: Main Pipeline\n",
    "- Video loading and preprocessing\n",
    "- Frame-by-frame processing\n",
    "- Result visualization\n",
    "- Output video generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Dependencies and Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\majorProj\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy import ndimage\n",
    "from sklearn.svm import SVC\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def download_file(url, filename):\n",
    "    \"\"\"Download files with progress bar\"\"\"\n",
    "    with tqdm(unit='B', unit_scale=True, miniters=1, desc=filename) as t:\n",
    "        urllib.request.urlretrieve(\n",
    "            url, \n",
    "            filename, \n",
    "            reporthook=lambda blocks, block_size, total_size: t.update(block_size)\n",
    "        )\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self, target_width=480, target_height=360):\n",
    "        self.target_width = target_width\n",
    "        self.target_height = target_height\n",
    "    \n",
    "    def read_video(self, video_path):\n",
    "        \"\"\"Read video and return resized frames\"\"\"\n",
    "        frames = []\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"Could not open video: {video_path}\")\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            # Resize frame to target dimensions\n",
    "            frame = cv2.resize(frame, (self.target_width, self.target_height))\n",
    "            frames.append(frame)\n",
    "        \n",
    "        cap.release()\n",
    "        return frames\n",
    "    \n",
    "    def write_video(self, output_path, frames, fps=30):\n",
    "        \"\"\"Write frames to video file\"\"\"\n",
    "        if not frames:\n",
    "            raise ValueError(\"No frames to write\")\n",
    "            \n",
    "        height, width = frames[0].shape[:2]\n",
    "        writer = cv2.VideoWriter(\n",
    "            output_path,\n",
    "            cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "            fps,\n",
    "            (width, height)\n",
    "        )\n",
    "        \n",
    "        for frame in frames:\n",
    "            writer.write(frame)\n",
    "        writer.release()\n",
    "\n",
    "# Utility functions for image processing\n",
    "def preprocess_frame(frame):\n",
    "    \"\"\"Preprocess frame for YOLO\"\"\"\n",
    "    # Convert BGR to RGB\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # Normalize\n",
    "    frame = frame.astype(np.float32) / 255.0\n",
    "    # Add batch dimension\n",
    "    frame = np.expand_dims(frame, axis=0)\n",
    "    return frame\n",
    "\n",
    "def draw_box(frame, box, color=(0, 255, 0), thickness=2, label=None):\n",
    "    \"\"\"Draw bounding box with optional label\"\"\"\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)\n",
    "    if label:\n",
    "        cv2.putText(frame, label, (x1, y1-10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)\n",
    "    return frame\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calculate Intersection over Union of two boxes\"\"\"\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    \n",
    "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "# Create necessary directories\n",
    "required_dirs = ['weights', 'config', 'output']\n",
    "for d in required_dirs:\n",
    "    os.makedirs(d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: YOLO Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class YOLODetector:\n",
    "    def __init__(self):\n",
    "        # Download YOLOv3 weights and config if not exists\n",
    "        self.weights_path = 'weights/yolov3.weights'\n",
    "        self.config_path = 'config/yolov3.cfg'\n",
    "        self.coco_names_path = 'config/coco.names'\n",
    "        self.download_yolo_files()\n",
    "        \n",
    "        # Load COCO class names\n",
    "        with open(self.coco_names_path, 'r') as f:\n",
    "            self.classes = f.read().strip().split('\\n')\n",
    "        \n",
    "        # Initialize network\n",
    "        self.net = cv2.dnn.readNetFromDarknet(self.config_path, self.weights_path)\n",
    "        self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "        self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "        \n",
    "        # Get output layer names - Fixed version\n",
    "        layer_names = self.net.getLayerNames()\n",
    "        unconnected_layers = self.net.getUnconnectedOutLayers()\n",
    "        self.output_layers = []\n",
    "        for i in unconnected_layers:\n",
    "            if isinstance(i, (list, np.ndarray)):\n",
    "                # Handle case where i is array-like\n",
    "                self.output_layers.append(layer_names[int(i[0] - 1)])\n",
    "            else:\n",
    "                # Handle case where i is scalar\n",
    "                self.output_layers.append(layer_names[int(i - 1)])\n",
    "        \n",
    "        # Vehicle classes we're interested in (car, truck, bus, motorcycle)\n",
    "        self.vehicle_classes = [2, 3, 5, 7]\n",
    "        \n",
    "    def download_yolo_files(self):\n",
    "        \"\"\"Download YOLOv3 weights and config files if not present\"\"\"\n",
    "        files = {\n",
    "            'weights': {\n",
    "                'path': self.weights_path,\n",
    "                'url': 'https://pjreddie.com/media/files/yolov3.weights'\n",
    "            },\n",
    "            'config': {\n",
    "                'path': self.config_path,\n",
    "                'url': 'https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg'\n",
    "            },\n",
    "            'names': {\n",
    "                'path': self.coco_names_path,\n",
    "                'url': 'https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for file_info in files.values():\n",
    "            if not os.path.exists(file_info['path']):\n",
    "                print(f\"Downloading {file_info['path']}...\")\n",
    "                download_file(file_info['url'], file_info['path'])\n",
    "\n",
    "    def detect(self, frame, conf_threshold=0.5, nms_threshold=0.4):\n",
    "        \"\"\"\n",
    "        Detect vehicles in frame\n",
    "        Returns: list of [class_id, x1, x2, y1, y2, confidence]\n",
    "        \"\"\"\n",
    "        height, width = frame.shape[:2]\n",
    "        \n",
    "        # Create blob from image\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), \n",
    "                                   swapRB=True, crop=False)\n",
    "        self.net.setInput(blob)\n",
    "        \n",
    "        # Forward pass\n",
    "        layer_outputs = self.net.forward(self.output_layers)\n",
    "        \n",
    "        # Initialize lists for detected boxes, confidences, and class IDs\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "        \n",
    "        # Process each layer output\n",
    "        for output in layer_outputs:\n",
    "            for detection in output:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                \n",
    "                # Filter for vehicle classes and confidence threshold\n",
    "                if class_id in self.vehicle_classes and confidence > conf_threshold:\n",
    "                    # Get box coordinates\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "                    \n",
    "                    # Rectangle coordinates\n",
    "                    x1 = int(center_x - w/2)\n",
    "                    y1 = int(center_y - h/2)\n",
    "                    x2 = x1 + w\n",
    "                    y2 = y1 + h\n",
    "                    \n",
    "                    boxes.append([x1, y1, x2, y2])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "        \n",
    "        # Apply non-maximum suppression\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "        \n",
    "        detections = []\n",
    "        if len(indices) > 0:\n",
    "            indices = indices.flatten()\n",
    "            for i in indices:\n",
    "                detections.append([\n",
    "                    class_ids[i],\n",
    "                    boxes[i][0], boxes[i][2],  # x1, x2\n",
    "                    boxes[i][1], boxes[i][3],  # y1, y2\n",
    "                    confidences[i]\n",
    "                ])\n",
    "        \n",
    "        return detections\n",
    "\n",
    "    def draw_detections(self, frame, detections):\n",
    "        \"\"\"Draw detection boxes on frame\"\"\"\n",
    "        frame_copy = frame.copy()\n",
    "        for detection in detections:\n",
    "            class_id, x1, x2, y1, y2, conf = detection\n",
    "            label = f\"{self.classes[class_id]}: {conf:.2f}\"\n",
    "            color = (0, 255, 0)  # Green for vehicles\n",
    "            draw_box(frame_copy, [x1, y1, x2, y2], color=color, label=label)\n",
    "        return frame_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: MOSSE Tracker and TCFI Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "class MOSSETracker:\n",
    "    def __init__(self, num_of_training_imgs=10, learning_rate=0.225, psr_threshold=10.0):\n",
    "        self.num_of_training_imgs = num_of_training_imgs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.psr_threshold = psr_threshold\n",
    "        \n",
    "        # Initialize tracking variables\n",
    "        self.dx = []  # x direction movement\n",
    "        self.dy = []  # y direction movement\n",
    "        self.centers = []  # tracking centers history\n",
    "        self.updated_last_time = True\n",
    "        self.good = True  # tracking status\n",
    "        \n",
    "    def init_tracker(self, frame, bbox):\n",
    "        \"\"\"Initialize tracker with first frame and bounding box\"\"\"\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        self.width = x2 - x1\n",
    "        self.height = y2 - y1\n",
    "        self.center = (x1 + self.width/2, y1 + self.height/2)\n",
    "        self.area = self.width * self.height\n",
    "        \n",
    "        # Get initial window\n",
    "        self.win = cv2.createHanningWindow((self.width, self.height), cv2.CV_32F)\n",
    "        \n",
    "        # Create Gaussian target\n",
    "        g = np.zeros((self.height, self.width), np.float32)\n",
    "        g[self.height//2, self.width//2] = 1\n",
    "        g = cv2.GaussianBlur(g, (-1, -1), 3.0)\n",
    "        g = g / g.max()\n",
    "        \n",
    "        # Convert to Fourier domain\n",
    "        self.G = cv2.dft(g, flags=cv2.DFT_COMPLEX_OUTPUT)\n",
    "        \n",
    "        # Initialize tracker\n",
    "        img = self.get_subwindow(frame, self.center)\n",
    "        self.prepare_initialization(frame, img)\n",
    "        \n",
    "    def prepare_initialization(self, frame, img):\n",
    "        \"\"\"Prepare initial tracking filters\"\"\"\n",
    "        self.H1 = np.zeros_like(self.G)\n",
    "        self.H2 = np.zeros_like(self.G)\n",
    "        \n",
    "        # Apply gaussian blur\n",
    "        img = cv2.GaussianBlur(img, (3, 3), 3)\n",
    "        \n",
    "        # Generate training examples\n",
    "        for _ in range(self.num_of_training_imgs):\n",
    "            transformed_img = self.random_warp(img)\n",
    "            H1, H2 = self.compute_filter(transformed_img)\n",
    "            self.H1 += H1\n",
    "            self.H2 += H2\n",
    "            \n",
    "        self.update_filter()\n",
    "        self.update_tracking(frame, False)\n",
    "        \n",
    "    def get_subwindow(self, frame, center):\n",
    "        \"\"\"Extract subwindow at center location\"\"\"\n",
    "        x, y = map(int, center)\n",
    "        x1 = max(0, x - self.width//2)\n",
    "        y1 = max(0, y - self.height//2)\n",
    "        x2 = min(frame.shape[1], x1 + self.width)\n",
    "        y2 = min(frame.shape[0], y1 + self.height)\n",
    "        \n",
    "        roi = frame[y1:y2, x1:x2]\n",
    "        if roi.shape[0] != self.height or roi.shape[1] != self.width:\n",
    "            roi = cv2.resize(roi, (self.width, self.height))\n",
    "        return roi.astype(np.float32)\n",
    "        \n",
    "    def preprocess(self, img):\n",
    "        \"\"\"Preprocess image for tracking\"\"\"\n",
    "        img = np.log(np.float32(img) + 1.0)\n",
    "        mean = img.mean()\n",
    "        std = img.std()\n",
    "        img = (img - mean) / (std + 1e-5)\n",
    "        return img * self.win\n",
    "        \n",
    "    def compute_filter(self, img):\n",
    "        \"\"\"Compute numerator and denominator of MOSSE filter\"\"\"\n",
    "        F = cv2.dft(self.preprocess(img), flags=cv2.DFT_COMPLEX_OUTPUT)\n",
    "        H1 = cv2.mulSpectrums(self.G, F, 0, conjB=True)\n",
    "        H2 = cv2.mulSpectrums(F, F, 0, conjB=True)\n",
    "        return H1, H2\n",
    "        \n",
    "    def update_filter(self):\n",
    "        \"\"\"Update MOSSE filter\"\"\"\n",
    "        self.H = self.compute_h_filter(self.H1, self.H2)\n",
    "        self.H[..., 1] *= -1  # conjugate for correlation\n",
    "        \n",
    "    def compute_h_filter(self, H1, H2):\n",
    "        \"\"\"Compute H filter from H1 and H2\"\"\"\n",
    "        Num_real, Num_imag = H1[..., 0], H1[..., 1]\n",
    "        Den_real, Den_imag = H2[..., 0], H2[..., 1]\n",
    "        \n",
    "        h_filter = (Num_real + 1j * Num_imag) / (Den_real + 1j * Den_imag)\n",
    "        return np.dstack([np.real(h_filter), np.imag(h_filter)]).copy()\n",
    "        \n",
    "    def correlate_and_update(self, img):\n",
    "        \"\"\"Correlate image with filter and update PSR\"\"\"\n",
    "        F = cv2.dft(img, flags=cv2.DFT_COMPLEX_OUTPUT)\n",
    "        C = cv2.mulSpectrums(F, self.H, 0, conjB=True)\n",
    "        response = cv2.idft(C, flags=cv2.DFT_SCALE | cv2.DFT_REAL_OUTPUT)\n",
    "        \n",
    "        h, w = response.shape\n",
    "        _, max_val, _, max_loc = cv2.minMaxLoc(response)\n",
    "        \n",
    "        # Calculate PSR (Peak to Sidelobe Ratio)\n",
    "        side_resp = response.copy()\n",
    "        side_resp[max(0, max_loc[1]-5):min(h, max_loc[1]+6),\n",
    "                 max(0, max_loc[0]-5):min(w, max_loc[0]+6)] = 0\n",
    "        mean = side_resp.mean()\n",
    "        std = side_resp.std()\n",
    "        psr = (max_val - mean) / (std + 1e-5)\n",
    "        \n",
    "        return psr, response, max_loc\n",
    "        \n",
    "    def update_tracking(self, frame, is_stopped=False):\n",
    "        \"\"\"Update tracking for current frame\"\"\"\n",
    "        if is_stopped and self.updated_last_time:\n",
    "            # Use TCFI - Track-compensated frame interpolation\n",
    "            dx = sum(self.dx[-3:]) / 3\n",
    "            dy = sum(self.dy[-3:]) / 3\n",
    "            self.center = self.center[0] + dx, self.center[1] + dy\n",
    "            self.dx.append(dx)\n",
    "            self.dy.append(dy)\n",
    "            self.updated_last_time = False\n",
    "            return\n",
    "            \n",
    "        self.updated_last_time = True\n",
    "        img = self.get_subwindow(frame, self.center)\n",
    "        img = cv2.GaussianBlur(img, (3, 3), 3)\n",
    "        img = self.preprocess(img)\n",
    "        \n",
    "        psr, response, (dx, dy) = self.correlate_and_update(img)\n",
    "        self.good = psr > self.psr_threshold\n",
    "        \n",
    "        if not self.good:\n",
    "            if not self.dx:\n",
    "                self.dx.append(0)\n",
    "                self.dy.append(0)\n",
    "            else:\n",
    "                self.dx.append(self.dx[-1])\n",
    "                self.dy.append(self.dy[-1])\n",
    "            self.center = (self.center[0] + self.dx[-1], \n",
    "                         self.center[1] + self.dy[-1])\n",
    "        else:\n",
    "            dx = dx - self.width/2\n",
    "            dy = dy - self.height/2\n",
    "            self.dx.append(dx)\n",
    "            self.dy.append(dy)\n",
    "            self.center = (self.center[0] + dx, self.center[1] + dy)\n",
    "            \n",
    "            # Update filter\n",
    "            img = self.get_subwindow(frame, self.center)\n",
    "            H1, H2 = self.compute_filter(img)\n",
    "            self.H1 = self.H1 * (1.0 - self.learning_rate) + H1 * self.learning_rate\n",
    "            self.H2 = self.H2 * (1.0 - self.learning_rate) + H2 * self.learning_rate\n",
    "            self.update_filter()\n",
    "            \n",
    "        self.centers.append((int(self.center[0]), int(self.center[1])))\n",
    "        return self.good\n",
    "        \n",
    "    def random_warp(self, img):\n",
    "        \"\"\"Apply random affine transform for training\"\"\"\n",
    "        height, width = img.shape[:2]\n",
    "        T = np.zeros((2, 3))\n",
    "        \n",
    "        perturb = 0.2\n",
    "        angle = (np.random.rand() - 0.5) * perturb\n",
    "        cos_val = np.cos(angle)\n",
    "        sin_val = np.sin(angle)\n",
    "        \n",
    "        T[:2, :2] = [[cos_val, -sin_val], [sin_val, cos_val]]\n",
    "        T[:2, :2] += (np.random.rand(2, 2) - 0.5) * perturb\n",
    "        T[:, 2] = (width/2, height/2) - np.dot(T[:2, :2], (width/2, height/2))\n",
    "        \n",
    "        return cv2.warpAffine(img, T, (width, height), \n",
    "                            borderMode=cv2.BORDER_REFLECT)\n",
    "\n",
    "class VehicleTracker:\n",
    "    def __init__(self, frame_width, frame_height, tracker_id=0):\n",
    "        self.frame_width = frame_width\n",
    "        self.frame_height = frame_height\n",
    "        self.tracker_id = tracker_id\n",
    "        self.history = []\n",
    "        self.tracker = None\n",
    "        \n",
    "    def init_track(self, frame, bbox):\n",
    "        \"\"\"Initialize tracking for a vehicle\"\"\"\n",
    "        self.tracker = MOSSETracker()\n",
    "        self.tracker.init_tracker(frame, bbox)\n",
    "        self.history.append(bbox)\n",
    "        \n",
    "    def update(self, frame):\n",
    "        \"\"\"Update tracking\"\"\"\n",
    "        if self.tracker is None:\n",
    "            return None\n",
    "            \n",
    "        # Check if vehicle is stopped\n",
    "        is_stopped = False\n",
    "        if len(self.tracker.dx) >= 3:\n",
    "            avg_speed = self.get_avg_speed(\n",
    "                len(self.tracker.dx)-3, \n",
    "                len(self.tracker.dx)\n",
    "            )\n",
    "            is_stopped = avg_speed < 20\n",
    "            \n",
    "        # Update tracking\n",
    "        self.tracker.update_tracking(frame, is_stopped)\n",
    "        current_bbox = self.get_current_bbox()\n",
    "        self.history.append(current_bbox)\n",
    "        return current_bbox\n",
    "        \n",
    "    def get_current_bbox(self):\n",
    "        \"\"\"Get current bounding box\"\"\"\n",
    "        x, y = self.tracker.center\n",
    "        w, h = self.tracker.width, self.tracker.height\n",
    "        return [\n",
    "            int(x - w/2), int(y - h/2),\n",
    "            int(x + w/2), int(y + h/2)\n",
    "        ]\n",
    "        \n",
    "    def get_avg_speed(self, start_frame=None, end_frame=None):\n",
    "        \"\"\"Calculate average speed\"\"\"\n",
    "        if not self.tracker.dx:\n",
    "            return 0\n",
    "            \n",
    "        if start_frame is None or end_frame is None:\n",
    "            dx_changes = self.tracker.dx\n",
    "            dy_changes = self.tracker.dy\n",
    "        else:\n",
    "            dx_changes = self.tracker.dx[start_frame:end_frame]\n",
    "            dy_changes = self.tracker.dy[start_frame:end_frame]\n",
    "            \n",
    "        avg_dx = sum(dx_changes) / len(dx_changes)\n",
    "        avg_dy = sum(dy_changes) / len(dy_changes)\n",
    "        speed = np.sqrt(avg_dx**2 + avg_dy**2)\n",
    "        return speed * self.get_speed_coefficient()\n",
    "        \n",
    "    def get_speed_coefficient(self):\n",
    "        \"\"\"Calculate speed coefficient based on vehicle area\"\"\"\n",
    "        coefficient = 43200 / self.tracker.area\n",
    "        return coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Crash Estimation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CrashEstimator:\n",
    "    def __init__(self, speed_limit=50, collision_threshold=40):\n",
    "        self.speed_limit = speed_limit  # Minimum speed to consider for crash estimation\n",
    "        self.collision_threshold = collision_threshold  # Distance threshold for collision detection\n",
    "        self.estimation_frames = [16, 19, 22, 25, 28]  # Frames to check for collision\n",
    "        \n",
    "    def estimate_future_position(self, tracker, frame_no):\n",
    "        \"\"\"Estimate vehicle position after 10 frames\"\"\"\n",
    "        if len(tracker.tracker.dx) < 5 or len(tracker.tracker.dx) > 20:\n",
    "            # Not enough history or too old tracker\n",
    "            return None, None, None, None\n",
    "        \n",
    "        # Calculate average movement from last 10 frames\n",
    "        measure = min(len(tracker.tracker.dx), 10)\n",
    "        expected_position_no = len(tracker.tracker.dx) + 10\n",
    "        \n",
    "        current_x, current_y = tracker.tracker.center\n",
    "        dx = sum(tracker.tracker.dx[-measure:]) / measure\n",
    "        dy = sum(tracker.tracker.dy[-measure:]) / measure\n",
    "        \n",
    "        # Predict future position\n",
    "        future_x = current_x + dx * measure\n",
    "        future_y = current_y + dy * measure\n",
    "        \n",
    "        # Get bounding box for future position\n",
    "        w, h = tracker.tracker.width, tracker.tracker.height\n",
    "        return (\n",
    "            int(future_x - w/2),  # x1\n",
    "            int(future_y - h/2),  # y1\n",
    "            int(future_x + w/2),  # x2\n",
    "            int(future_y + h/2)   # y2\n",
    "        )\n",
    "    \n",
    "    def check_speed(self, tracker, frame_no):\n",
    "        \"\"\"Check if vehicle speed is above threshold\"\"\"\n",
    "        if frame_no < 10:\n",
    "            return False\n",
    "            \n",
    "        current_speed = tracker.get_avg_speed(frame_no-10, frame_no)\n",
    "        return current_speed > self.speed_limit\n",
    "    \n",
    "    def calculate_distance(self, pos1, pos2):\n",
    "        \"\"\"Calculate distance between centers of two positions\"\"\"\n",
    "        if not pos1 or not pos2:\n",
    "            return float('inf')\n",
    "            \n",
    "        center1 = ((pos1[0] + pos1[2])/2, (pos1[1] + pos1[3])/2)\n",
    "        center2 = ((pos2[0] + pos2[2])/2, (pos2[1] + pos2[3])/2)\n",
    "        \n",
    "        return np.sqrt(\n",
    "            (center1[0] - center2[0])**2 + \n",
    "            (center1[1] - center2[1])**2\n",
    "        )\n",
    "    \n",
    "    def calculate_trajectory_deviation(self, tracker, frame_no, future_pos):\n",
    "        \"\"\"Calculate deviation between predicted and actual trajectory\"\"\"\n",
    "        if not future_pos:\n",
    "            return float('inf')\n",
    "            \n",
    "        current_x, current_y = tracker.tracker.center\n",
    "        future_center = ((future_pos[0] + future_pos[2])/2,\n",
    "                        (future_pos[1] + future_pos[3])/2)\n",
    "        \n",
    "        actual_x, actual_y = tracker.tracker.centers[frame_no]\n",
    "        \n",
    "        deviation = np.sqrt(\n",
    "            (actual_x - future_center[0])**2 + \n",
    "            (actual_y - future_center[1])**2\n",
    "        )\n",
    "        return deviation\n",
    "    \n",
    "    def detect_collision(self, tracker_a, tracker_b, frame_no):\n",
    "        \"\"\"Detect potential collision between two vehicles\"\"\"\n",
    "        # Check if either vehicle is moving fast enough\n",
    "        if not (self.check_speed(tracker_a, frame_no) or \n",
    "                self.check_speed(tracker_b, frame_no)):\n",
    "            return False\n",
    "        \n",
    "        # Get future positions\n",
    "        future_pos_a = self.estimate_future_position(tracker_a, frame_no)\n",
    "        future_pos_b = self.estimate_future_position(tracker_b, frame_no)\n",
    "        \n",
    "        # Calculate distance between future positions\n",
    "        future_distance = self.calculate_distance(future_pos_a, future_pos_b)\n",
    "        \n",
    "        # If vehicles are too far apart, no collision\n",
    "        if future_distance > self.collision_threshold:\n",
    "            return False\n",
    "        \n",
    "        # Calculate trajectory deviations\n",
    "        dev_a = self.calculate_trajectory_deviation(tracker_a, frame_no, future_pos_a)\n",
    "        dev_b = self.calculate_trajectory_deviation(tracker_b, frame_no, future_pos_b)\n",
    "        \n",
    "        # If maximum deviation is significant compared to distance\n",
    "        max_deviation = max(dev_a, dev_b)\n",
    "        if 2 * max_deviation > future_distance:\n",
    "            return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def estimate_crashes(self, trackers, frame_no):\n",
    "        \"\"\"Estimate crashes between all tracked vehicles\"\"\"\n",
    "        crash_pairs = []\n",
    "        \n",
    "        # Check each pair of trackers\n",
    "        for i, tracker_a in enumerate(trackers):\n",
    "            for j, tracker_b in enumerate(trackers[i+1:], i+1):\n",
    "                # Only check at specific frames\n",
    "                if frame_no not in self.estimation_frames:\n",
    "                    continue\n",
    "                    \n",
    "                if self.detect_collision(tracker_a, tracker_b, frame_no):\n",
    "                    crash_pairs.append((i, j))\n",
    "        \n",
    "        return crash_pairs\n",
    "\n",
    "    def annotate_crash_estimation(self, frame, trackers, crash_pairs):\n",
    "        \"\"\"Draw crash estimation visualizations on frame\"\"\"\n",
    "        frame_copy = frame.copy()\n",
    "        \n",
    "        # Draw current positions and trajectories\n",
    "        for tracker in trackers:\n",
    "            if len(tracker.tracker.centers) < 2:\n",
    "                continue\n",
    "                \n",
    "            # Draw trajectory\n",
    "            centers = tracker.tracker.centers[-10:]\n",
    "            for i in range(len(centers)-1):\n",
    "                pt1 = tuple(map(int, centers[i]))\n",
    "                pt2 = tuple(map(int, centers[i+1]))\n",
    "                cv2.line(frame_copy, pt1, pt2, (0, 255, 0), 1)\n",
    "            \n",
    "            # Draw current position\n",
    "            bbox = tracker.get_current_bbox()\n",
    "            if tracker.tracker.good:\n",
    "                color = (0, 255, 0)  # Green for good tracking\n",
    "            else:\n",
    "                color = (0, 0, 255)  # Red for poor tracking\n",
    "            draw_box(frame_copy, bbox, color)\n",
    "        \n",
    "        # Highlight crash predictions\n",
    "        for i, j in crash_pairs:\n",
    "            tracker_a = trackers[i]\n",
    "            tracker_b = trackers[j]\n",
    "            \n",
    "            # Draw connecting line between vehicles\n",
    "            center_a = tracker_a.tracker.center\n",
    "            center_b = tracker_b.tracker.center\n",
    "            cv2.line(frame_copy, \n",
    "                    tuple(map(int, center_a)),\n",
    "                    tuple(map(int, center_b)),\n",
    "                    (0, 0, 255), 2)\n",
    "            \n",
    "            # Draw warning text\n",
    "            text_pos = (\n",
    "                int((center_a[0] + center_b[0])/2),\n",
    "                int((center_a[1] + center_b[1])/2) - 10\n",
    "            )\n",
    "            cv2.putText(frame_copy, \"CRASH RISK!\",\n",
    "                       text_pos,\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                       0.5, (0, 0, 255), 2)\n",
    "        \n",
    "        return frame_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: ViF (Violent Flow) Descriptor & SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ViolentFlowDescriptor:\n",
    "    def __init__(self, subsample=3, n_bins=20):\n",
    "        self.subsample = subsample  # Frame subsampling rate\n",
    "        self.n_bins = n_bins  # Number of histogram bins\n",
    "        self.cell_size = (4, 4)  # Size of grid cells\n",
    "        self.hs = HornSchunck()  # Horn-Schunck optical flow\n",
    "        \n",
    "    def compute_flow_magnitude(self, prev_frame, curr_frame):\n",
    "        \"\"\"Compute optical flow magnitude using Horn-Schunck\"\"\"\n",
    "        # Calculate optical flow\n",
    "        u, v, _ = self.hs.process(prev_frame, curr_frame)\n",
    "        # Calculate magnitude\n",
    "        magnitude = np.sqrt(u*u + v*v)\n",
    "        return magnitude\n",
    "    \n",
    "    def create_histogram(self, flow_map):\n",
    "        \"\"\"Create histogram of flow magnitudes\"\"\"\n",
    "        # Normalize flow map to [0,1]\n",
    "        if flow_map.max() != 0:\n",
    "            flow_map = flow_map / flow_map.max()\n",
    "            \n",
    "        hist, _ = np.histogram(\n",
    "            flow_map, \n",
    "            bins=self.n_bins, \n",
    "            range=(0, 1), \n",
    "            density=True\n",
    "        )\n",
    "        return hist\n",
    "    \n",
    "    def compute_binary_map(self, magnitude_changes):\n",
    "        \"\"\"Compute binary significance map\"\"\"\n",
    "        # Calculate adaptive threshold\n",
    "        threshold = np.mean(np.abs(magnitude_changes))\n",
    "        return (np.abs(magnitude_changes) >= threshold).astype(np.float32)\n",
    "    \n",
    "    def extract_features(self, frames):\n",
    "        \"\"\"Extract ViF features from sequence of frames\"\"\"\n",
    "        if len(frames) < 30:\n",
    "            raise ValueError(\"Need at least 30 frames\")\n",
    "            \n",
    "        height, width = frames[0].shape[:2]\n",
    "        n_cells_y = height // self.cell_size[0]\n",
    "        n_cells_x = width // self.cell_size[1]\n",
    "        \n",
    "        # Initialize feature vector\n",
    "        feature_vector = np.zeros((n_cells_y * n_cells_x * self.n_bins,))\n",
    "        \n",
    "        # Process frames with subsampling\n",
    "        flow_maps = []\n",
    "        for i in range(0, len(frames)-self.subsample, self.subsample):\n",
    "            prev_frame = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)\n",
    "            curr_frame = cv2.cvtColor(frames[i+self.subsample], \n",
    "                                    cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            magnitude = self.compute_flow_magnitude(prev_frame, curr_frame)\n",
    "            flow_maps.append(magnitude)\n",
    "            \n",
    "        # Compute magnitude changes\n",
    "        magnitude_changes = np.zeros_like(flow_maps[0])\n",
    "        for i in range(len(flow_maps)-1):\n",
    "            magnitude_changes += np.abs(flow_maps[i+1] - flow_maps[i])\n",
    "        magnitude_changes /= len(flow_maps)-1\n",
    "        \n",
    "        # Compute binary map\n",
    "        binary_map = self.compute_binary_map(magnitude_changes)\n",
    "        \n",
    "        # Compute histograms for each cell\n",
    "        idx = 0\n",
    "        for y in range(n_cells_y):\n",
    "            for x in range(n_cells_x):\n",
    "                # Extract cell\n",
    "                cell = binary_map[\n",
    "                    y*self.cell_size[0]:(y+1)*self.cell_size[0],\n",
    "                    x*self.cell_size[1]:(x+1)*self.cell_size[1]\n",
    "                ]\n",
    "                # Compute histogram for cell\n",
    "                hist = self.create_histogram(cell)\n",
    "                # Add to feature vector\n",
    "                feature_vector[idx:idx+self.n_bins] = hist\n",
    "                idx += self.n_bins\n",
    "                \n",
    "        return feature_vector\n",
    "\n",
    "class HornSchunck:\n",
    "    \"\"\"Horn-Schunck optical flow implementation\"\"\"\n",
    "    def __init__(self, alpha=0.001, iterations=8):\n",
    "        self.alpha = alpha\n",
    "        self.iterations = iterations\n",
    "        \n",
    "    def process(self, frame1, frame2):\n",
    "        \"\"\"Compute optical flow using Horn-Schunck method\"\"\"\n",
    "        # Convert to float32\n",
    "        frame1 = frame1.astype(np.float32) / 255.0\n",
    "        frame2 = frame2.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Compute gradients\n",
    "        kernel_x = np.array([[-1, 1], [-1, 1]]) * 0.25\n",
    "        kernel_y = np.array([[-1, -1], [1, 1]]) * 0.25\n",
    "        kernel_t = np.ones((2, 2)) * 0.25\n",
    "        \n",
    "        fx = signal.convolve2d(frame1, kernel_x, 'same') + \\\n",
    "             signal.convolve2d(frame2, kernel_x, 'same')\n",
    "        fy = signal.convolve2d(frame1, kernel_y, 'same') + \\\n",
    "             signal.convolve2d(frame2, kernel_y, 'same')\n",
    "        ft = signal.convolve2d(frame1, -kernel_t, 'same') + \\\n",
    "             signal.convolve2d(frame2, kernel_t, 'same')\n",
    "        \n",
    "        # Initialize velocity\n",
    "        u = np.zeros_like(frame1)\n",
    "        v = np.zeros_like(frame1)\n",
    "        \n",
    "        # Iterate\n",
    "        for _ in range(self.iterations):\n",
    "            # Compute local averages\n",
    "            u_avg = signal.convolve2d(u, np.ones((3,3))/9, 'same')\n",
    "            v_avg = signal.convolve2d(v, np.ones((3,3))/9, 'same')\n",
    "            \n",
    "            # Update velocities\n",
    "            den = fx*fx + fy*fy + self.alpha\n",
    "            num_u = fx*u_avg + fy*v_avg + ft\n",
    "            num_v = fx*u_avg + fy*v_avg + ft\n",
    "            \n",
    "            u = u_avg - fx * num_u / den\n",
    "            v = v_avg - fy * num_v / den\n",
    "            \n",
    "        return u, v, np.sqrt(u*u + v*v)\n",
    "\n",
    "class CrashClassifier:\n",
    "    def __init__(self):\n",
    "        self.vif = ViolentFlowDescriptor()\n",
    "        self.svm = SVC(kernel='poly', probability=True)\n",
    "        \n",
    "    def train(self, crash_sequences, non_crash_sequences):\n",
    "        \"\"\"Train SVM classifier with ViF features\"\"\"\n",
    "        # Extract features\n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        # Process crash sequences\n",
    "        for seq in crash_sequences:\n",
    "            features = self.vif.extract_features(seq)\n",
    "            X.append(features)\n",
    "            y.append(1)\n",
    "            \n",
    "        # Process non-crash sequences\n",
    "        for seq in non_crash_sequences:\n",
    "            features = self.vif.extract_features(seq)\n",
    "            X.append(features)\n",
    "            y.append(0)\n",
    "            \n",
    "        # Train SVM\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        self.svm.fit(X, y)\n",
    "        \n",
    "    def predict(self, sequence):\n",
    "        \"\"\"Predict crash probability for sequence\"\"\"\n",
    "        features = self.vif.extract_features(sequence)\n",
    "        prob = self.svm.predict_proba([features])[0][1]\n",
    "        return prob\n",
    "    \n",
    "    def save_model(self, path=\"models/crash_classifier.pkl\"):\n",
    "        \"\"\"Save trained model\"\"\"\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(self.svm, f)\n",
    "            \n",
    "    def load_model(self, path=\"models/crash_classifier.pkl\"):\n",
    "        \"\"\"Load trained model\"\"\"\n",
    "        with open(path, 'rb') as f:\n",
    "            self.svm = pickle.load(f)\n",
    "\n",
    "def extract_vehicle_sequence(frames, tracker, length=30):\n",
    "    \"\"\"Extract sequence of frames for a vehicle\"\"\"\n",
    "    sequence = []\n",
    "    for frame_idx, bbox in enumerate(tracker.history[-length:]):\n",
    "        if frame_idx >= len(frames):\n",
    "            break\n",
    "            \n",
    "        frame = frames[frame_idx].copy()\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        roi = frame[y1:y2, x1:x2]\n",
    "        \n",
    "        if roi.size == 0:\n",
    "            continue\n",
    "            \n",
    "        # Resize to standard size\n",
    "        roi = cv2.resize(roi, (64, 64))\n",
    "        sequence.append(roi)\n",
    "        \n",
    "    return sequence if len(sequence) == length else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Main Pipeline and Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pre-trained crash classifier found. Only using crash estimation.\n",
      "Loading video...\n",
      "Processing 304 frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/304 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing video: OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-q3d_8t8e\\opencv\\modules\\imgproc\\src\\phasecorr.cpp:606: error: (-215:Assertion failed) winSize.width > 1 && winSize.height > 1 in function 'cv::createHanningWindow'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Section 6: Main Pipeline and Visualization\n",
    "\n",
    "class AccidentDetectionPipeline:\n",
    "    def __init__(self):\n",
    "        # Initialize all components\n",
    "        self.video_processor = VideoProcessor()\n",
    "        self.detector = YOLODetector()\n",
    "        self.crash_estimator = CrashEstimator()\n",
    "        self.crash_classifier = CrashClassifier()\n",
    "        \n",
    "        # Load pre-trained crash classifier if available\n",
    "        try:\n",
    "            self.crash_classifier.load_model()\n",
    "        except:\n",
    "            print(\"No pre-trained crash classifier found. Only using crash estimation.\")\n",
    "        \n",
    "        self.trackers = []\n",
    "        self.tracker_ids = 0\n",
    "        \n",
    "    def process_video(self, video_path, output_path=None):\n",
    "        \"\"\"Process video for accident detection\"\"\"\n",
    "        print(\"Loading video...\")\n",
    "        frames = self.video_processor.read_video(video_path)\n",
    "        if not frames:\n",
    "            raise ValueError(\"Could not load video\")\n",
    "            \n",
    "        output_frames = []\n",
    "        self.trackers = []\n",
    "        self.tracker_ids = 0\n",
    "        \n",
    "        print(f\"Processing {len(frames)} frames...\")\n",
    "        for frame_idx, frame in enumerate(tqdm(frames)):\n",
    "            processed_frame = self.process_frame(frame, frame_idx)\n",
    "            output_frames.append(processed_frame)\n",
    "            \n",
    "        if output_path:\n",
    "            print(\"Saving output video...\")\n",
    "            self.video_processor.write_video(output_path, output_frames)\n",
    "            \n",
    "        return output_frames\n",
    "    \n",
    "    def process_frame(self, frame, frame_idx):\n",
    "        \"\"\"Process single frame\"\"\"\n",
    "        frame_annotated = frame.copy()\n",
    "        \n",
    "        # Vehicle Detection (every 30 frames)\n",
    "        if frame_idx % 30 == 0:\n",
    "            detections = self.detector.detect(frame)\n",
    "            self.initialize_new_trackers(frame, detections)\n",
    "            \n",
    "        # Update trackers\n",
    "        valid_trackers = []\n",
    "        for tracker in self.trackers:\n",
    "            current_bbox = tracker.update(frame)\n",
    "            if current_bbox:\n",
    "                valid_trackers.append(tracker)\n",
    "                \n",
    "        self.trackers = valid_trackers\n",
    "        \n",
    "        # Crash Estimation\n",
    "        crash_pairs = self.crash_estimator.estimate_crashes(\n",
    "            self.trackers, frame_idx)\n",
    "        \n",
    "        # Verify crashes with ViF if classifier is available\n",
    "        verified_crashes = []\n",
    "        for i, j in crash_pairs:\n",
    "            is_verified = True\n",
    "            if hasattr(self, 'crash_classifier'):\n",
    "                # Get sequences for both vehicles\n",
    "                seq_i = extract_vehicle_sequence(\n",
    "                    frames[-30:], self.trackers[i])\n",
    "                seq_j = extract_vehicle_sequence(\n",
    "                    frames[-30:], self.trackers[j])\n",
    "                \n",
    "                if seq_i is not None and seq_j is not None:\n",
    "                    is_verified = (\n",
    "                        self.crash_classifier.predict(seq_i) > 0.5 or \n",
    "                        self.crash_classifier.predict(seq_j) > 0.5\n",
    "                    )\n",
    "            \n",
    "            if is_verified:\n",
    "                verified_crashes.append((i, j))\n",
    "        \n",
    "        # Annotate frame\n",
    "        frame_annotated = self.annotate_frame(\n",
    "            frame_annotated, \n",
    "            frame_idx,\n",
    "            verified_crashes\n",
    "        )\n",
    "        \n",
    "        return frame_annotated\n",
    "    \n",
    "    def initialize_new_trackers(self, frame, detections):\n",
    "        \"\"\"Initialize trackers for new detections\"\"\"\n",
    "        if not detections:\n",
    "            return\n",
    "            \n",
    "        # Initialize new tracker for each detection\n",
    "        for detection in detections:\n",
    "            tracker = VehicleTracker(\n",
    "                self.video_processor.target_width,\n",
    "                self.video_processor.target_height,\n",
    "                self.tracker_ids\n",
    "            )\n",
    "            self.tracker_ids += 1\n",
    "            \n",
    "            bbox = detection[1:5]  # x1, x2, y1, y2\n",
    "            tracker.init_track(frame, bbox)\n",
    "            self.trackers.append(tracker)\n",
    "            \n",
    "    def annotate_frame(self, frame, frame_idx, crash_pairs):\n",
    "        \"\"\"Annotate frame with detections, tracks, and crashes\"\"\"\n",
    "        # Draw tracker paths and boxes\n",
    "        for tracker in self.trackers:\n",
    "            # Draw trajectory\n",
    "            if len(tracker.history) > 1:\n",
    "                for i in range(len(tracker.history)-1):\n",
    "                    pt1 = (\n",
    "                        int((tracker.history[i][0] + tracker.history[i][2])/2),\n",
    "                        int((tracker.history[i][1] + tracker.history[i][3])/2)\n",
    "                    )\n",
    "                    pt2 = (\n",
    "                        int((tracker.history[i+1][0] + tracker.history[i+1][2])/2),\n",
    "                        int((tracker.history[i+1][1] + tracker.history[i+1][3])/2)\n",
    "                    )\n",
    "                    cv2.line(frame, pt1, pt2, (0, 255, 0), 1)\n",
    "            \n",
    "            # Draw current box\n",
    "            bbox = tracker.history[-1]\n",
    "            speed = tracker.get_avg_speed()\n",
    "            label = f\"ID: {tracker.tracker_id} Speed: {speed:.1f}\"\n",
    "            color = (0, 255, 0) if speed < self.crash_estimator.speed_limit else (0, 165, 255)\n",
    "            draw_box(frame, bbox, color=color, label=label)\n",
    "        \n",
    "        # Highlight crashes\n",
    "        for i, j in crash_pairs:\n",
    "            tracker_a = self.trackers[i]\n",
    "            tracker_b = self.trackers[j]\n",
    "            \n",
    "            # Draw warning box around crash area\n",
    "            bbox_a = tracker_a.history[-1]\n",
    "            bbox_b = tracker_b.history[-1]\n",
    "            \n",
    "            x1 = min(bbox_a[0], bbox_b[0])\n",
    "            y1 = min(bbox_a[1], bbox_b[1])\n",
    "            x2 = max(bbox_a[2], bbox_b[2])\n",
    "            y2 = max(bbox_a[3], bbox_b[3])\n",
    "            \n",
    "            # Expand warning box\n",
    "            padding = 20\n",
    "            x1 = max(0, x1 - padding)\n",
    "            y1 = max(0, y1 - padding)\n",
    "            x2 = min(frame.shape[1], x2 + padding)\n",
    "            y2 = min(frame.shape[0], y2 + padding)\n",
    "            \n",
    "            # Draw warning box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            \n",
    "            # Add warning text\n",
    "            warning_text = \"CRASH DETECTED!\"\n",
    "            text_size = cv2.getTextSize(\n",
    "                warning_text, \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                1, \n",
    "                2\n",
    "            )[0]\n",
    "            \n",
    "            text_x = int((x1 + x2 - text_size[0])/2)\n",
    "            text_y = int(y1 - 10)\n",
    "            \n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                warning_text,\n",
    "                (text_x, text_y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1,\n",
    "                (0, 0, 255),\n",
    "                2\n",
    "            )\n",
    "        \n",
    "        # Add frame information\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            f\"Frame: {frame_idx}\",\n",
    "            (10, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1,\n",
    "            (255, 255, 255),\n",
    "            2\n",
    "        )\n",
    "        \n",
    "        return frame\n",
    "\n",
    "def visualize_detection(frame, detections):\n",
    "    \"\"\"Visualize detections on a single frame\"\"\"\n",
    "    frame_viz = frame.copy()\n",
    "    for detection in detections:\n",
    "        bbox = detection[1:5]\n",
    "        conf = detection[5]\n",
    "        draw_box(frame_viz, bbox, label=f\"Conf: {conf:.2f}\")\n",
    "    return frame_viz\n",
    "\n",
    "def main():\n",
    "    # Initialize pipeline\n",
    "    pipeline = AccidentDetectionPipeline()\n",
    "    \n",
    "    # Process video\n",
    "    input_video = \"C:\\\\Users\\\\HP\\\\OneDrive\\\\Documents\\\\mini projects\\\\testing\\\\Argus\\\\videos\\\\1508.mp4\"\n",
    "    output_video = \"output_video.mp4\"\n",
    "    \n",
    "    try:\n",
    "        output_frames = pipeline.process_video(input_video, output_video)\n",
    "        print(f\"Processing complete. Output saved to {output_video}\")\n",
    "        \n",
    "        # Display sample frames\n",
    "        sample_frames = [\n",
    "            output_frames[i] for i in range(0, len(output_frames), 30)\n",
    "        ]\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for i, frame in enumerate(sample_frames[:6]):\n",
    "            plt.subplot(2, 3, i+1)\n",
    "            plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"Frame {i*30}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "majorProj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
